{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0dd752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Cleaning and Preprocessing\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Optional: Run once if needed\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "\n",
    "df = pd.read_csv(\"original reviews.csv\")\n",
    "df.columns = df.columns.str.strip().str.title()\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "standard_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "custom_stopwords = set([...])  # use your full custom stopword list here\n",
    "\n",
    "synonym_map = { ... }  # use your full synonym dictionary here\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in standard_stopwords]\n",
    "    return ' '.join(words)\n",
    "\n",
    "def remove_custom_stopwords(text):\n",
    "    return ' '.join([word for word in text.split() if word not in custom_stopwords])\n",
    "\n",
    "def normalize_synonyms(text):\n",
    "    for phrase, replacement in synonym_map.items():\n",
    "        text = re.sub(r'\\b' + re.escape(phrase) + r'\\b', replacement, text)\n",
    "    return text\n",
    "\n",
    "df['Cleaned_Review'] = df['Review'].apply(clean_text).apply(normalize_synonyms).apply(remove_custom_stopwords)\n",
    "df.to_csv(\"mba_reviews_cleaned.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7a8b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Topic Modeling with BERTopic\n",
    "from bertopic import BERTopic\n",
    "\n",
    "df = pd.read_csv(\"mba_reviews_cleaned.csv\")\n",
    "df.columns = df.columns.str.strip()\n",
    "docs = df['Cleaned_Review'].fillna('').tolist()\n",
    "\n",
    "topic_model = BERTopic(language=\"english\", top_n_words=10, verbose=True, min_topic_size=5, n_gram_range=(1, 2))\n",
    "topics, _ = topic_model.fit_transform(docs)\n",
    "\n",
    "df['BERTopic_Label'] = topics\n",
    "df.to_csv(\"mba_reviews_with_topics.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e48b002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Merge & Rename Topics\n",
    "def merge_topics(topic):\n",
    "    if topic in [3, 5]:\n",
    "        return '3_5'\n",
    "    elif topic in [7, 9]:\n",
    "        return '7_9'\n",
    "    else:\n",
    "        return str(topic)\n",
    "\n",
    "df['Merged_Topic'] = df['BERTopic_Label'].apply(merge_topics)\n",
    "\n",
    "topic_rename_map = {\n",
    "    '0': 'finance',\n",
    "    '1': 'community',\n",
    "    '2': 'consulting',\n",
    "    '3_5': 'class quality',\n",
    "    '4': 'location',\n",
    "    '6': 'professor',\n",
    "    '7_9': 'entrepreneurship',\n",
    "    '8': 'course difficulty'\n",
    "}\n",
    "\n",
    "counts = df.groupby(['School', 'Merged_Topic']).size().unstack(fill_value=0)\n",
    "percent = counts.div(counts.sum(axis=1), axis=0)\n",
    "\n",
    "counts_named = counts.rename(columns=topic_rename_map)\n",
    "percent_named = percent.rename(columns=topic_rename_map)\n",
    "\n",
    "counts_named.to_csv(\"school_topic_counts_named.csv\")\n",
    "percent_named.to_csv(\"school_topic_percent_named.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24df1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Heatmap Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"school_topic_percent_named.csv\")\n",
    "df.set_index(\"School\", inplace=True)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.heatmap(df, annot=True, cmap=\"YlGnBu\", fmt=\".2f\", linewidths=0.5, cbar_kws={'label': 'Proportion'})\n",
    "plt.title(\"Topic Heatmap by School\", fontsize=20)\n",
    "plt.xticks(rotation=45, ha=\"right\", fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
